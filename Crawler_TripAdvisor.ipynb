{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert the url：https://www.tripadvisor.com/Restaurant_Review-g186299-d16693790-Reviews-Tim_s_Bistro-Southampton_Hampshire_England.html\n",
      "insert the filename:tt\n",
      "insert the number of pages:2\n",
      "start crawling\n",
      "success for crawler : https://www.tripadvisor.com/Restaurant_Review-g186299-d16693790-Reviews-Tim_s_Bistro-Southampton_Hampshire_England.html\n",
      "success for crawler : https://www.tripadvisor.com//Restaurant_Review-g186299-d16693790-Reviews-or10-Tim_s_Bistro-Southampton_Hampshire_England.html\n",
      "ttis already save to .csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# url = 'https://www.tripadvisor.com/Restaurant_Review-g186299-d11909730-Reviews-or10-Cosmo-Southampton_Hampshire_England.html'\n",
    "\n",
    "\n",
    "def crawl_review_container(link, filename, pages):\n",
    "    url = link\n",
    "    pages = int(pages)\n",
    "    visit_dates = []\n",
    "    titles = []\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    visit_ids = []\n",
    "    for round in range(pages):\n",
    "        res = requests.get(url)\n",
    "\n",
    "        html_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "        # 開始爬資料\n",
    "        review_containers = html_soup.find_all('div', class_='review-container')\n",
    "\n",
    "        for container in review_containers:\n",
    "            # date_of_visit\n",
    "            visit_date = container.find('div', class_='prw_rup prw_reviews_stay_date_hsx')\n",
    "            visit_date = visit_date.text[15:]\n",
    "            visit_dates.append(visit_date)\n",
    "\n",
    "            # titles\n",
    "            title = container.find('span', attrs={'class': 'noQuotes'})\n",
    "            title = title.text\n",
    "            titles.append(title)\n",
    "\n",
    "            # review\n",
    "            review = container.find('p', class_='partial_entry')\n",
    "            review = review.text\n",
    "            reviews.append(review)\n",
    "\n",
    "            # rating\n",
    "            rating = container.find('div', attrs={'ui_column is-9'})\n",
    "            rating = int(rating.span['class'][1][7:]) / 10\n",
    "            ratings.append(rating)\n",
    "\n",
    "            # ID\n",
    "            visit_id = container.find('div', attrs={'class': 'memberOverlayLink clickable'})['id'][-9:]\n",
    "            visit_id = int(visit_id)\n",
    "            visit_ids.append(visit_id)\n",
    "\n",
    "        paging_url = html_soup.select('div.mobile-more a')[15]['href']\n",
    "\n",
    "        next_url = 'https://www.tripadvisor.com/' + paging_url\n",
    "\n",
    "        print('success for crawler :', url)\n",
    "        \n",
    "        url = next_url\n",
    "\n",
    "        time.sleep(20)\n",
    "    # save to csv\n",
    "    df = pd.DataFrame({'rating': ratings,\n",
    "                       'review': reviews,\n",
    "                       'title': titles,\n",
    "                       'user_id': visit_ids,\n",
    "                       'visit_date': visit_dates\n",
    "                       })\n",
    "\n",
    "    df.to_csv( filename +'.csv', encoding='utf-8')\n",
    "    df = pd.read_csv(filename+'.csv')\n",
    "    df.head()\n",
    "\n",
    "\n",
    "crawl = input('insert the url：')\n",
    "csv_name = input('insert the filename:')\n",
    "pages = input('insert the number of pages:')\n",
    "print('start crawling')\n",
    "crawl_review_container(crawl, csv_name, pages)\n",
    "print(csv_name + 'is already save to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
